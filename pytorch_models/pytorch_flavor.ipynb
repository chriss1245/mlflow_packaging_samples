{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packaging a pytorch model with the pytorch flavor\n",
    "\n",
    "The pytorch flavor is the original flavor that supports mlflow. It has some cool features such as autologing. But you can not customize that much.\n",
    "\n",
    "**NOTE:** In order for the network to work, if you are using float32 (which is usual), you need to explicitly convert it. From the mlflow server, we will recieve float64."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import SimpleNN, RandomDataset, Trainer\n",
    "\n",
    "from mlflow.pytorch import save_model\n",
    "from mlflow.models.signature import infer_signature\n",
    "import requests\n",
    "import subprocess\n",
    "import torch\n",
    "import shutil\n",
    "import os\n",
    "import signal\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 10\n",
    "TARGET_SIZE = 2\n",
    "SERVE_PORT = 10001\n",
    "MODEL_PATH = \"model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13 [00:00<?, ?it/s]/home/ubuntu/miniconda3/envs/mlflow_pytorch/lib/python3.11/site-packages/torch/autograd/graph.py:825: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "loss: 1.07: 100%|██████████| 13/13 [00:00<00:00, 657.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 1.05: 100%|██████████| 13/13 [00:00<00:00, 943.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Loss: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 1.03: 100%|██████████| 13/13 [00:00<00:00, 972.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Loss: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 1.04: 100%|██████████| 13/13 [00:00<00:00, 937.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Loss: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 1.02: 100%|██████████| 13/13 [00:00<00:00, 952.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Loss: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 1.00: 100%|██████████| 13/13 [00:00<00:00, 970.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Loss: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 1.02: 100%|██████████| 13/13 [00:00<00:00, 945.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Loss: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 1.03: 100%|██████████| 13/13 [00:00<00:00, 1068.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Loss: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.98: 100%|██████████| 13/13 [00:00<00:00, 1061.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Loss: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.97: 100%|██████████| 13/13 [00:00<00:00, 978.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Loss: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = SimpleNN(input_size=INPUT_SIZE, output_size=TARGET_SIZE, hidden_size=10)\n",
    "\n",
    "train_dataset = RandomDataset(feat_size=INPUT_SIZE, target_size=TARGET_SIZE, num_samples=100)\n",
    "\n",
    "trainer = Trainer(model, optimizer=torch.optim.Adam(model.parameters()), loss_fn=torch.nn.MSELoss())\n",
    "\n",
    "trained_model = trainer.train(train_dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Packaging the model\n",
    "In order to package it you can use `save_model` passing the torch model, the code path and the environment it needs. Also... it is advisable to pass the model signature.\n",
    "\n",
    "For the environment I prefer to use conda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inputs: \n",
       "  [Tensor('float32', (-1, 10))]\n",
       "outputs: \n",
       "  [Tensor('float32', (-1, 2))]\n",
       "params: \n",
       "  None"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# signature\n",
    "input_example = torch.rand(1, INPUT_SIZE)\n",
    "output_example = trained_model(input_example)\n",
    "signature = infer_signature(input_example.numpy(), output_example.detach().numpy())\n",
    "signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda env\n",
    "# you usually want to save this to a file and then load it with mlflow\n",
    "conda_env = {\n",
    "    \"channels\": [\"defaults\"],\n",
    "    \"dependencies\": [\n",
    "        \"python\",\n",
    "        {\"pip\": [\"mlflow\", \"torch\", \"tqdm\"]}\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "shutil.rmtree(MODEL_PATH, ignore_errors=True)\n",
    "save_model(trained_model, MODEL_PATH, conda_env=conda_env, signature=signature, code_paths=[\"src\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Local serving\n",
    "\n",
    "You can inmediately serve this model and run inference in local. \n",
    "\n",
    "**Note:** With this you may not need docker. It is enough with having correclty set up the conda env."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 8/8 [00:00<00:00, 18672.47it/s]\n",
      "2024/12/01 23:19:29 INFO mlflow.models.flavor_backend_registry: Selected backend for flavor 'python_function'\n",
      "2024/12/01 23:19:29 INFO mlflow.pyfunc.backend: === Running command 'exec gunicorn --timeout=60 -b 127.0.0.1:10001 -w 2 ${GUNICORN_CMD_ARGS} -- mlflow.pyfunc.scoring_server.wsgi:app'\n",
      "[2024-12-01 23:19:30 +0100] [392037] [INFO] Starting gunicorn 23.0.0\n",
      "[2024-12-01 23:19:30 +0100] [392037] [INFO] Listening at: http://127.0.0.1:10001 (392037)\n",
      "[2024-12-01 23:19:30 +0100] [392037] [INFO] Using worker: sync\n",
      "[2024-12-01 23:19:30 +0100] [392038] [INFO] Booting worker with pid: 392038\n",
      "[2024-12-01 23:19:30 +0100] [392039] [INFO] Booting worker with pid: 392039\n"
     ]
    }
   ],
   "source": [
    "# start model server\n",
    "cmd = f\"mlflow models serve -m {MODEL_PATH} -p {SERVE_PORT} --env-manager local --workers 2\" # alternative: --env-manager conda: will create a new conda env\n",
    "process = subprocess.Popen(cmd, shell=True, preexec_fn=os.setsid)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': [[0.0012273788452148438, 0.30130383372306824]]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/mlflow_pytorch/lib/python3.11/site-packages/torch/cuda/__init__.py:129: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/mlflow_pytorch/lib/python3.11/site-packages/torch/cuda/__init__.py:129: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "result = requests.post(f\"http://localhost:{SERVE_PORT}/invocations\", json={\"inputs\": input_example.numpy().tolist()})\n",
    "print(result.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-01 23:19:34 +0100] [392039] [INFO] Worker exiting (pid: 392039)\n",
      "[2024-12-01 23:19:34 +0100] [392038] [INFO] Worker exiting (pid: 392038)\n",
      "[2024-12-01 23:19:34 +0100] [392037] [INFO] Handling signal: term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-01 23:19:35 +0100] [392037] [INFO] Shutting down: Master\n"
     ]
    }
   ],
   "source": [
    "# stop model server\n",
    "os.killpg(os.getpgid(process.pid), signal.SIGTERM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Docker\n",
    "\n",
    "We also can package the model in docker. It is usually easier this way. It works in your machine and in their machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Packaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_NAME = \"mlflow-model:pytorch\" # the name is mlflow-model and the tag is pytorch (you can change it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/mlflow_pytorch/lib/python3.11/site-packages/click/core.py:2362: UserWarning: Use of conda is discouraged. If you use it, please ensure that your use of conda complies with Anaconda's terms of service (https://legal.anaconda.com/policies/en/?name=terms-of-service). virtualenv is the recommended tool for environment reproducibility. To suppress this warning, set the MLFLOW_DISABLE_ENV_MANAGER_CONDA_WARNING environment variable to 'TRUE'.\n",
      "  value = self.callback(ctx, self, value)\n",
      "Downloading artifacts: 100%|██████████| 10/10 [00:00<00:00, 18078.90it/s]\n",
      "2024/12/01 23:24:44 INFO mlflow.models.flavor_backend_registry: Selected backend for flavor 'python_function'\n",
      "Downloading artifacts: 100%|██████████| 10/10 [00:00<00:00, 10007.88it/s]\n",
      "2024/12/01 23:24:44 INFO mlflow.pyfunc.backend: Building docker image with name mlflow-model:pytorch\n",
      "#0 building with \"default\" instance using docker driver\n",
      "\n",
      "#1 [internal] load build definition from Dockerfile\n",
      "#1 transferring dockerfile: 1.95kB done\n",
      "#1 DONE 0.0s\n",
      "\n",
      "#2 [internal] load metadata for docker.io/library/ubuntu:20.04\n",
      "#2 DONE 0.8s\n",
      "\n",
      "#3 [internal] load .dockerignore\n",
      "#3 transferring context: 2B done\n",
      "#3 DONE 0.0s\n",
      "\n",
      "#4 [ 1/15] FROM docker.io/library/ubuntu:20.04@sha256:8e5c4f0285ecbb4ead070431d29b576a530d3166df73ec44affc1cd27555141b\n",
      "#4 DONE 0.0s\n",
      "\n",
      "#5 [internal] load build context\n",
      "#5 transferring context: 12.78kB done\n",
      "#5 DONE 0.0s\n",
      "\n",
      "#6 [ 4/15] RUN bash ./miniconda.sh -b -p /miniconda && rm ./miniconda.sh\n",
      "#6 CACHED\n",
      "\n",
      "#7 [ 5/15] RUN apt-get install -y --no-install-recommends openjdk-11-jdk maven\n",
      "#7 CACHED\n",
      "\n",
      "#8 [ 7/15] RUN pip install mlflow==2.18.0\n",
      "#8 CACHED\n",
      "\n",
      "#9 [ 8/15] RUN mvn --batch-mode dependency:copy -Dartifact=org.mlflow:mlflow-scoring:2.18.0:pom -DoutputDirectory=/opt/java\n",
      "#9 CACHED\n",
      "\n",
      "#10 [ 2/15] RUN apt-get -y update && DEBIAN_FRONTEND=noninteractive TZ=Etc/UTC apt-get install -y --no-install-recommends wget curl nginx ca-certificates bzip2 build-essential cmake git-core\n",
      "#10 CACHED\n",
      "\n",
      "#11 [ 6/15] WORKDIR /opt/mlflow\n",
      "#11 CACHED\n",
      "\n",
      "#12 [10/15] RUN cp /opt/java/mlflow-scoring-2.18.0.pom /opt/java/pom.xml\n",
      "#12 CACHED\n",
      "\n",
      "#13 [ 3/15] RUN curl --fail -L https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh > miniconda.sh\n",
      "#13 CACHED\n",
      "\n",
      "#14 [ 9/15] RUN mvn --batch-mode dependency:copy -Dartifact=org.mlflow:mlflow-scoring:2.18.0:jar -DoutputDirectory=/opt/java/jars\n",
      "#14 CACHED\n",
      "\n",
      "#15 [11/15] RUN cd /opt/java && mvn --batch-mode dependency:copy-dependencies -DoutputDirectory=/opt/java/jars\n",
      "#15 CACHED\n",
      "\n",
      "#16 [12/15] COPY model_dir/model /opt/ml/model\n",
      "#16 DONE 0.0s\n",
      "\n",
      "#17 [13/15] RUN python -c \"from mlflow.models import container as C; C._install_pyfunc_deps('/opt/ml/model', install_mlflow=False, enable_mlserver=False, env_manager='conda');\"\n",
      "#17 1.526 2024/12/01 22:24:47 INFO mlflow.models.container: creating and activating custom environment\n",
      "#17 1.817 /miniconda/lib/python3.12/argparse.py:2006: FutureWarning: `remote_definition` is deprecated and will be removed in 25.9. Use `conda env create --file=URL` instead.\n",
      "#17 1.817   action(self, namespace, argument_values, option_string)\n",
      "#17 1.830 Warning: you have pip-installed dependencies in your environment file, but you do not list pip itself as one of your conda dependencies.  Conda may not use the correct pip to install your packages, and they may end up in the wrong place.  Please add an explicit pip dependency.  I'm adding one for you, but still nagging you.\n",
      "#17 2.002 Channels:\n",
      "#17 2.002  - defaults\n",
      "#17 2.002 Platform: linux-64\n",
      "#17 2.002 Collecting package metadata (repodata.json): ...working... done\n",
      "#17 4.604 Solving environment: ...working... done\n",
      "#17 7.883 \n",
      "#17 7.883 Downloading and Extracting Packages: ...working... done\n",
      "#17 7.883 Preparing transaction: ...working... done\n",
      "#17 8.289 Verifying transaction: ...working... done\n",
      "#17 9.471 Executing transaction: ...working... done\n",
      "#17 13.15 Installing pip dependencies: ...working... Ran pip subprocess with arguments:\n",
      "#17 185.0 ['/miniconda/envs/custom_env/bin/python', '-m', 'pip', 'install', '-U', '-r', '/opt/mlflow/condaenv.fflkcxrk.requirements.txt', '--exists-action=b']\n",
      "#17 185.0 Pip subprocess output:\n",
      "#17 185.0 Collecting mlflow (from -r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Using cached mlflow-2.18.0-py3-none-any.whl.metadata (29 kB)\n",
      "#17 185.0 Collecting torch (from -r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 2))\n",
      "#17 185.0   Downloading torch-2.5.1-cp313-cp313-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "#17 185.0 Collecting tqdm (from -r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 3))\n",
      "#17 185.0   Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "#17 185.0 Collecting mlflow-skinny==2.18.0 (from mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Using cached mlflow_skinny-2.18.0-py3-none-any.whl.metadata (30 kB)\n",
      "#17 185.0 Collecting Flask<4 (from mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Using cached flask-3.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "#17 185.0 Collecting alembic!=1.10.0,<2 (from mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Using cached alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "#17 185.0 Collecting docker<8,>=4.0.0 (from mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Using cached docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "#17 185.0 Collecting graphene<4 (from mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Using cached graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
      "#17 185.0 Collecting markdown<4,>=3.3 (from mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "#17 185.0 Collecting matplotlib<4 (from mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Downloading matplotlib-3.9.3-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "#17 185.0 Collecting numpy<3 (from mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Downloading numpy-2.1.3-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "#17 185.0 Collecting pandas<3 (from mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Downloading pandas-2.2.3-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "#17 185.0 Collecting pyarrow<19,>=4.0.0 (from mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Downloading pyarrow-18.1.0-cp313-cp313-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "#17 185.0 Collecting scikit-learn<2 (from mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Downloading scikit_learn-1.5.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "#17 185.0 Collecting scipy<2 (from mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Downloading scipy-1.14.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "#17 185.0 Collecting sqlalchemy<3,>=1.4.0 (from mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Downloading SQLAlchemy-2.0.36-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
      "#17 185.0 Collecting Jinja2<4,>=2.11 (from mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "#17 185.0 Collecting gunicorn<24 (from mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Using cached gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "#17 185.0 Collecting cachetools<6,>=5.0.0 (from mlflow-skinny==2.18.0->mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Using cached cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "#17 185.0 Collecting click<9,>=7.0 (from mlflow-skinny==2.18.0->mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "#17 185.0 Collecting cloudpickle<4 (from mlflow-skinny==2.18.0->mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Using cached cloudpickle-3.1.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "#17 185.0 Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.18.0->mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Using cached databricks_sdk-0.38.0-py3-none-any.whl.metadata (38 kB)\n",
      "#17 185.0 Collecting gitpython<4,>=3.1.9 (from mlflow-skinny==2.18.0->mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Using cached GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "#17 185.0 Collecting importlib-metadata!=4.7.0,<9,>=3.7.0 (from mlflow-skinny==2.18.0->mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Using cached importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "#17 185.0 Collecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==2.18.0->mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Using cached opentelemetry_api-1.28.2-py3-none-any.whl.metadata (1.4 kB)\n",
      "#17 185.0 Collecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==2.18.0->mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Using cached opentelemetry_sdk-1.28.2-py3-none-any.whl.metadata (1.5 kB)\n",
      "#17 185.0 Collecting packaging<25 (from mlflow-skinny==2.18.0->mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "#17 185.0 Collecting protobuf<6,>=3.12.0 (from mlflow-skinny==2.18.0->mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Using cached protobuf-5.29.0-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "#17 185.0 Collecting pyyaml<7,>=5.1 (from mlflow-skinny==2.18.0->mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Downloading PyYAML-6.0.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "#17 185.0 Collecting requests<3,>=2.17.3 (from mlflow-skinny==2.18.0->mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "#17 185.0 Collecting sqlparse<1,>=0.4.0 (from mlflow-skinny==2.18.0->mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Using cached sqlparse-0.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "#17 185.0 Collecting filelock (from torch->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 2))\n",
      "#17 185.0   Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "#17 185.0 Collecting typing-extensions>=4.8.0 (from torch->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 2))\n",
      "#17 185.0   Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "#17 185.0 Collecting networkx (from torch->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 2))\n",
      "#17 185.0   Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "#17 185.0 Collecting fsspec (from torch->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 2))\n",
      "#17 185.0   Downloading fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "#17 185.0 Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 2))\n",
      "#17 185.0   Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "#17 185.0 Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 2))\n",
      "#17 185.0   Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "#17 185.0 Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 2))\n",
      "#17 185.0   Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "#17 185.0 Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 2))\n",
      "#17 185.0   Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "#17 185.0 Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 2))\n",
      "#17 185.0   Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "#17 185.0 Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 2))\n",
      "#17 185.0   Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "#17 185.0 Collecting nvidia-curand-cu12==10.3.5.147 (from torch->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 2))\n",
      "#17 185.0   Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "#17 185.0 Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 2))\n",
      "#17 185.0   Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "#17 185.0 Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 2))\n",
      "#17 185.0   Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "#17 185.0 Collecting nvidia-nccl-cu12==2.21.5 (from torch->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 2))\n",
      "#17 185.0   Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "#17 185.0 Collecting nvidia-nvtx-cu12==12.4.127 (from torch->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 2))\n",
      "#17 185.0   Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "#17 185.0 Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 2))\n",
      "#17 185.0   Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "#17 185.0 Requirement already satisfied: setuptools in /miniconda/envs/custom_env/lib/python3.13/site-packages (from torch->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 2)) (75.1.0)\n",
      "#17 185.0 Collecting sympy==1.13.1 (from torch->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 2))\n",
      "#17 185.0   Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "#17 185.0 Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 2))\n",
      "#17 185.0   Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "#17 185.0 Collecting Mako (from alembic!=1.10.0,<2->mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Using cached Mako-1.3.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "#17 185.0 Collecting urllib3>=1.26.0 (from docker<8,>=4.0.0->mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "#17 185.0 Collecting Werkzeug>=3.1 (from Flask<4->mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "#17 185.0 Collecting itsdangerous>=2.2 (from Flask<4->mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Using cached itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "#17 185.0 Collecting blinker>=1.9 (from Flask<4->mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Using cached blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "#17 185.0 Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Using cached graphql_core-3.2.5-py3-none-any.whl.metadata (10 kB)\n",
      "#17 185.0 Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Using cached graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "#17 185.0 Collecting python-dateutil<3,>=2.7.0 (from graphene<4->mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "#17 185.0 Collecting MarkupSafe>=2.0 (from Jinja2<4,>=2.11->mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Downloading MarkupSafe-3.0.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "#17 185.0 Collecting contourpy>=1.0.1 (from matplotlib<4->mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Downloading contourpy-1.3.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
      "#17 185.0 Collecting cycler>=0.10 (from matplotlib<4->mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "#17 185.0 Collecting fonttools>=4.22.0 (from matplotlib<4->mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Downloading fonttools-4.55.0-cp313-cp313-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (164 kB)\n",
      "#17 185.0 Collecting kiwisolver>=1.3.1 (from matplotlib<4->mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Downloading kiwisolver-1.4.7-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.3 kB)\n",
      "#17 185.0 Collecting pillow>=8 (from matplotlib<4->mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Downloading pillow-11.0.0-cp313-cp313-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
      "#17 185.0 Collecting pyparsing>=2.3.1 (from matplotlib<4->mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Using cached pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "#17 185.0 Collecting pytz>=2020.1 (from pandas<3->mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Using cached pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "#17 185.0 Collecting tzdata>=2022.7 (from pandas<3->mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Using cached tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "#17 185.0 Collecting joblib>=1.2.0 (from scikit-learn<2->mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "#17 185.0 Collecting threadpoolctl>=3.1.0 (from scikit-learn<2->mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "#17 185.0 Collecting google-auth~=2.0 (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Using cached google_auth-2.36.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "#17 185.0 Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=3.1.9->mlflow-skinny==2.18.0->mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Using cached gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "#17 185.0 Collecting zipp>=3.20 (from importlib-metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.18.0->mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Using cached zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "#17 185.0 Collecting deprecated>=1.2.6 (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Using cached Deprecated-1.2.15-py2.py3-none-any.whl.metadata (5.5 kB)\n",
      "#17 185.0 Collecting opentelemetry-semantic-conventions==0.49b2 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Using cached opentelemetry_semantic_conventions-0.49b2-py3-none-any.whl.metadata (2.3 kB)\n",
      "#17 185.0 Collecting six>=1.5 (from python-dateutil<3,>=2.7.0->graphene<4->mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Using cached six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "#17 185.0 Collecting charset-normalizer<4,>=2 (from requests<3,>=2.17.3->mlflow-skinny==2.18.0->mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Downloading charset_normalizer-3.4.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\n",
      "#17 185.0 Collecting idna<4,>=2.5 (from requests<3,>=2.17.3->mlflow-skinny==2.18.0->mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "#17 185.0 Collecting certifi>=2017.4.17 (from requests<3,>=2.17.3->mlflow-skinny==2.18.0->mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Downloading certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "#17 185.0 Collecting wrapt<2,>=1.10 (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Downloading wrapt-1.17.0-cp313-cp313-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "#17 185.0 Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.18.0->mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Using cached smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "#17 185.0 Collecting pyasn1-modules>=0.2.1 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Using cached pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "#17 185.0 Collecting rsa<5,>=3.1.4 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "#17 185.0 Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow->-r /opt/mlflow/condaenv.fflkcxrk.requirements.txt (line 1))\n",
      "#17 185.0   Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "#17 185.0 Using cached mlflow-2.18.0-py3-none-any.whl (27.3 MB)\n",
      "#17 185.0 Using cached mlflow_skinny-2.18.0-py3-none-any.whl (5.8 MB)\n",
      "#17 185.0 Downloading torch-2.5.1-cp313-cp313-manylinux1_x86_64.whl (906.4 MB)\n",
      "#17 185.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 906.4/906.4 MB 22.2 MB/s eta 0:00:00\n",
      "#17 185.0 Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "#17 185.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 363.4/363.4 MB 30.8 MB/s eta 0:00:00\n",
      "#17 185.0 Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "#17 185.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.8/13.8 MB 30.3 MB/s eta 0:00:00\n",
      "#17 185.0 Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "#17 185.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 24.6/24.6 MB 30.8 MB/s eta 0:00:00\n",
      "#17 185.0 Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "#17 185.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 883.7/883.7 kB 27.3 MB/s eta 0:00:00\n",
      "#17 185.0 Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "#17 185.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 664.8/664.8 MB 31.2 MB/s eta 0:00:00\n",
      "#17 185.0 Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "#17 185.0    ━━━━━━━━━━━━━━━━━━���━━━━━━━━━━━━━━━━━━━━━ 211.5/211.5 MB 31.4 MB/s eta 0:00:00\n",
      "#17 185.0 Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "#17 185.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.3/56.3 MB 31.3 MB/s eta 0:00:00\n",
      "#17 185.0 Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "#17 185.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 127.9/127.9 MB 31.4 MB/s eta 0:00:00\n",
      "#17 185.0 Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "#17 185.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 207.5/207.5 MB 32.1 MB/s eta 0:00:00\n",
      "#17 185.0 Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "#17 185.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 188.7/188.7 MB 30.8 MB/s eta 0:00:00\n",
      "#17 185.0 Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "#17 185.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 21.1/21.1 MB 29.4 MB/s eta 0:00:00\n",
      "#17 185.0 Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "#17 185.0 Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "#17 185.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.2/6.2 MB 32.4 MB/s eta 0:00:00\n",
      "#17 185.0 Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "#17 185.0 Using cached alembic-1.14.0-py3-none-any.whl (233 kB)\n",
      "#17 185.0 Using cached docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "#17 185.0 Using cached flask-3.1.0-py3-none-any.whl (102 kB)\n",
      "#17 185.0 Using cached graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
      "#17 185.0 Using cached gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
      "#17 185.0 Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "#17 185.0 Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "#17 185.0 Downloading matplotlib-3.9.3-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "#17 185.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.3/8.3 MB 31.9 MB/s eta 0:00:00\n",
      "#17 185.0 Downloading numpy-2.1.3-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
      "#17 185.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.0/16.0 MB 29.2 MB/s eta 0:00:00\n",
      "#17 185.0 Downloading pandas-2.2.3-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "#17 185.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━��━━━━━━━━━━━━ 12.7/12.7 MB 31.8 MB/s eta 0:00:00\n",
      "#17 185.0 Downloading pyarrow-18.1.0-cp313-cp313-manylinux_2_28_x86_64.whl (40.1 MB)\n",
      "#17 185.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.1/40.1 MB 27.9 MB/s eta 0:00:00\n",
      "#17 185.0 Downloading scikit_learn-1.5.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "#17 185.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.0/13.0 MB 23.0 MB/s eta 0:00:00\n",
      "#17 185.0 Downloading scipy-1.14.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (40.8 MB)\n",
      "#17 185.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.8/40.8 MB 18.9 MB/s eta 0:00:00\n",
      "#17 185.0 Downloading SQLAlchemy-2.0.36-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "#17 185.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.2/3.2 MB 26.1 MB/s eta 0:00:00\n",
      "#17 185.0 Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "#17 185.0 Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "#17 185.0 Downloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "#17 185.0 Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "#17 185.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 22.2 MB/s eta 0:00:00\n",
      "#17 185.0 Using cached blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "#17 185.0 Using cached cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "#17 185.0 Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "#17 185.0 Using cached cloudpickle-3.1.0-py3-none-any.whl (22 kB)\n",
      "#17 185.0 Downloading contourpy-1.3.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (322 kB)\n",
      "#17 185.0 Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "#17 185.0 Using cached databricks_sdk-0.38.0-py3-none-any.whl (575 kB)\n",
      "#17 185.0 Downloading fonttools-4.55.0-cp313-cp313-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "#17 185.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.9/4.9 MB 29.9 MB/s eta 0:00:00\n",
      "#17 185.0 Using cached GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "#17 185.0 Using cached graphql_core-3.2.5-py3-none-any.whl (203 kB)\n",
      "#17 185.0 Using cached graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "#17 185.0 Using cached importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\n",
      "#17 185.0 Using cached itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "#17 185.0 Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "#17 185.0 Downloading kiwisolver-1.4.7-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
      "#17 185.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━��━━━━━━━━━━━━ 1.5/1.5 MB 22.3 MB/s eta 0:00:00\n",
      "#17 185.0 Downloading MarkupSafe-3.0.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
      "#17 185.0 Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "#17 185.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 536.2/536.2 kB 16.1 MB/s eta 0:00:00\n",
      "#17 185.0 Using cached opentelemetry_api-1.28.2-py3-none-any.whl (64 kB)\n",
      "#17 185.0 Using cached opentelemetry_sdk-1.28.2-py3-none-any.whl (118 kB)\n",
      "#17 185.0 Using cached opentelemetry_semantic_conventions-0.49b2-py3-none-any.whl (159 kB)\n",
      "#17 185.0 Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
      "#17 185.0 Downloading pillow-11.0.0-cp313-cp313-manylinux_2_28_x86_64.whl (4.4 MB)\n",
      "#17 185.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.4/4.4 MB 28.0 MB/s eta 0:00:00\n",
      "#17 185.0 Using cached protobuf-5.29.0-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "#17 185.0 Using cached pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "#17 185.0 Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "#17 185.0 Using cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "#17 185.0 Downloading PyYAML-6.0.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (759 kB)\n",
      "#17 185.0    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 759.5/759.5 kB 21.6 MB/s eta 0:00:00\n",
      "#17 185.0 Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "#17 185.0 Using cached sqlparse-0.5.2-py3-none-any.whl (44 kB)\n",
      "#17 185.0 Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "#17 185.0 Using cached tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "#17 185.0 Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "#17 185.0 Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "#17 185.0 Using cached Mako-1.3.6-py3-none-any.whl (78 kB)\n",
      "#17 185.0 Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "#17 185.0 Downloading charset_normalizer-3.4.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
      "#17 185.0 Using cached Deprecated-1.2.15-py2.py3-none-any.whl (9.9 kB)\n",
      "#17 185.0 Using cached gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "#17 185.0 Using cached google_auth-2.36.0-py2.py3-none-any.whl (209 kB)\n",
      "#17 185.0 Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "#17 185.0 Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "#17 185.0 Using cached zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "#17 185.0 Using cached pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "#17 185.0 Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "#17 185.0 Using cached smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "#17 185.0 Downloading wrapt-1.17.0-cp313-cp313-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (89 kB)\n",
      "#17 185.0 Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "#17 185.0 Installing collected packages: pytz, mpmath, zipp, wrapt, urllib3, tzdata, typing-extensions, tqdm, threadpoolctl, sympy, sqlparse, smmap, six, pyyaml, pyparsing, pyasn1, pyarrow, protobuf, pillow, packaging, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, markdown, kiwisolver, joblib, itsdangerous, idna, graphql-core, fsspec, fonttools, filelock, cycler, cloudpickle, click, charset-normalizer, certifi, cachetools, blinker, Werkzeug, sqlalchemy, scipy, rsa, requests, python-dateutil, pyasn1-modules, nvidia-cusparse-cu12, nvidia-cudnn-cu12, Mako, Jinja2, importlib-metadata, gunicorn, graphql-relay, gitdb, deprecated, contourpy, scikit-learn, pandas, opentelemetry-api, nvidia-cusolver-cu12, matplotlib, graphene, google-auth, gitpython, Flask, docker, alembic, torch, opentelemetry-semantic-conventions, databricks-sdk, opentelemetry-sdk, mlflow-skinny, mlflow\n",
      "#17 185.0 Successfully installed Flask-3.1.0 Jinja2-3.1.4 Mako-1.3.6 MarkupSafe-3.0.2 Werkzeug-3.1.3 alembic-1.14.0 blinker-1.9.0 cachetools-5.5.0 certifi-2024.8.30 charset-normalizer-3.4.0 click-8.1.7 cloudpickle-3.1.0 contourpy-1.3.1 cycler-0.12.1 databricks-sdk-0.38.0 deprecated-1.2.15 docker-7.1.0 filelock-3.16.1 fonttools-4.55.0 fsspec-2024.10.0 gitdb-4.0.11 gitpython-3.1.43 google-auth-2.36.0 graphene-3.4.3 graphql-core-3.2.5 graphql-relay-3.2.0 gunicorn-23.0.0 idna-3.10 importlib-metadata-8.5.0 itsdangerous-2.2.0 joblib-1.4.2 kiwisolver-1.4.7 markdown-3.7 matplotlib-3.9.3 mlflow-2.18.0 mlflow-skinny-2.18.0 mpmath-1.3.0 networkx-3.4.2 numpy-2.1.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 opentelemetry-api-1.28.2 opentelemetry-sdk-1.28.2 opentelemetry-semantic-conventions-0.49b2 packaging-24.2 pandas-2.2.3 pillow-11.0.0 protobuf-5.29.0 pyarrow-18.1.0 pyasn1-0.6.1 pyasn1-modules-0.4.1 pyparsing-3.2.0 python-dateutil-2.9.0.post0 pytz-2024.2 pyyaml-6.0.2 requests-2.32.3 rsa-4.9 scikit-learn-1.5.2 scipy-1.14.1 six-1.16.0 smmap-5.0.1 sqlalchemy-2.0.36 sqlparse-0.5.2 sympy-1.13.1 threadpoolctl-3.5.0 torch-2.5.1 tqdm-4.67.1 typing-extensions-4.12.2 tzdata-2024.2 urllib3-2.2.3 wrapt-1.17.0 zipp-3.21.0\n",
      "#17 185.0 \n",
      "#17 185.0 done\n",
      "#17 185.0 #\n",
      "#17 185.0 # To activate this environment, use\n",
      "#17 185.0 #\n",
      "#17 185.0 #     $ conda activate custom_env\n",
      "#17 185.0 #\n",
      "#17 185.0 # To deactivate an active environment, use\n",
      "#17 185.0 #\n",
      "#17 185.0 #     $ conda deactivate\n",
      "#17 185.0 \n",
      "#17 186.5 Requirement already satisfied: gunicorn[gevent] in /miniconda/envs/custom_env/lib/python3.13/site-packages (23.0.0)\n",
      "#17 186.5 Requirement already satisfied: packaging in /miniconda/envs/custom_env/lib/python3.13/site-packages (from gunicorn[gevent]) (24.2)\n",
      "#17 186.9 Collecting gevent>=1.4.0 (from gunicorn[gevent])\n",
      "#17 187.1   Downloading gevent-24.11.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "#17 187.1 Collecting zope.event (from gevent>=1.4.0->gunicorn[gevent])\n",
      "#17 187.1   Downloading zope.event-5.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "#17 187.2 Collecting zope.interface (from gevent>=1.4.0->gunicorn[gevent])\n",
      "#17 187.3   Downloading zope.interface-7.2-cp313-cp313-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (44 kB)\n",
      "#17 187.4 Collecting greenlet>=3.1.1 (from gevent>=1.4.0->gunicorn[gevent])\n",
      "#17 187.4   Downloading greenlet-3.1.1-cp313-cp313-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "#17 187.4 Requirement already satisfied: setuptools in /miniconda/envs/custom_env/lib/python3.13/site-packages (from zope.event->gevent>=1.4.0->gunicorn[gevent]) (75.1.0)\n",
      "#17 187.5 Downloading gevent-24.11.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.8 MB)\n",
      "#17 187.7    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.8/6.8 MB 30.2 MB/s eta 0:00:00\n",
      "#17 187.7 Downloading greenlet-3.1.1-cp313-cp313-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (615 kB)\n",
      "#17 187.8    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 615.6/615.6 kB 25.1 MB/s eta 0:00:00\n",
      "#17 187.8 Downloading zope.event-5.0-py3-none-any.whl (6.8 kB)\n",
      "#17 187.8 Downloading zope.interface-7.2-cp313-cp313-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
      "#17 188.3 Installing collected packages: zope.interface, zope.event, greenlet, gevent\n",
      "#17 189.0 Successfully installed gevent-24.11.1 greenlet-3.1.1 zope.event-5.0 zope.interface-7.2\n",
      "#17 189.0 WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
      "#17 DONE 189.5s\n",
      "\n",
      "#18 [14/15] RUN chmod o+rwX /opt/mlflow/\n",
      "#18 DONE 0.1s\n",
      "\n",
      "#19 [15/15] RUN rm -rf /var/lib/apt/lists/*\n",
      "#19 DONE 0.2s\n",
      "\n",
      "#20 exporting to image\n",
      "#20 exporting layers\n",
      "#20 exporting layers 29.6s done\n",
      "#20 writing image sha256:b117192d740d31c230993b31e80ee05e2813f339c8150da3dde27c7dad3a7f7f done\n",
      "#20 naming to docker.io/library/mlflow-model:pytorch done\n",
      "#20 DONE 29.6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='mlflow models build-docker -m model -n mlflow-model:pytorch --env-manager conda', returncode=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmd = f\"mlflow models build-docker -m {MODEL_PATH} -n {IMAGE_NAME} --env-manager conda\"\n",
    "subprocess.run(cmd, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Inference\n",
    "In order to get predictions we need to run the docker image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTAINER_NAME = \"mlflow_server\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-12-01 22:40:28 +0000] [41] [INFO] Starting gunicorn 23.0.0\n",
      "[2024-12-01 22:40:28 +0000] [41] [INFO] Listening at: http://127.0.0.1:8000 (41)\n",
      "[2024-12-01 22:40:28 +0000] [41] [INFO] Using worker: sync\n",
      "[2024-12-01 22:40:28 +0000] [47] [INFO] Booting worker with pid: 47\n",
      "2024/12/01 22:40:29 WARNING mlflow.pyfunc: The version of Python that the model was saved in, `Python 3.11.10`, differs from the version of Python that is currently running, `Python 3.13.0`, and may be incompatible\n"
     ]
    }
   ],
   "source": [
    "cmd  = f'docker run -e GUNICORN_CMD_ARGS=\"--workers=1\"  -p {SERVE_PORT}:8080 --name {CONTAINER_NAME} {IMAGE_NAME}'\n",
    "\n",
    "process = subprocess.Popen(cmd, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172.17.0.1 - - [01/Dec/2024:22:40:38 +0000] \"POST /invocations HTTP/1.1\" 200 63 \"-\" \"python-requests/2.32.3\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'predictions': [[0.0012273788452148438, 0.30130383372306824]]}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = requests.post(f\"http://0.0.0.0:{SERVE_PORT}/invocations\", json={\"inputs\": input_example.numpy().tolist()})\n",
    "result.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/01 22:40:47 INFO mlflow.models.container: Got sigterm signal, exiting.\n",
      "[2024-12-01 22:40:47 +0000] [41] [INFO] Handling signal: term\n",
      "[2024-12-01 22:40:47 +0000] [47] [INFO] Worker exiting (pid: 47)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlflow_server\n",
      "mlflow_server\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='docker rm mlflow_server', returncode=0)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmd_stop = f\"docker stop {CONTAINER_NAME}\"\n",
    "subprocess.run(cmd_stop, shell=True)\n",
    "\n",
    "cmd_rm = f\"docker rm {CONTAINER_NAME}\"\n",
    "subprocess.run(cmd_rm, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3. Exporting the docker image\n",
    "In order to use the docker image in other machines, we need to compress it and upload it to the machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='docker save -o model.tar mlflow-model:pytorch', returncode=0)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmd = \"docker save -o model.tar mlflow-model:pytorch\"\n",
    "subprocess.run(cmd, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4. Importing the docker image\n",
    "The target machine needs to have docker installed. Then we can load the image and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = \"docker load -i model.tar\"\n",
    "subprocess.run(cmd, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can do inference in the target machine executing the same command as in step 6.2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
